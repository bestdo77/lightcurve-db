
Ran tool
下面是本目录下每个主要文件的用途说明及使用方法（建议保存为 `目录说明.md` 或 `files_overview.md`）：

---

# TDengine 目录文件说明与使用方法

## 1. 主要脚本与功能

| 文件名 | 作用说明 | 使用方法 |
|--------|----------|----------|
| `generate_astronomical_data.py` | 生成天文观测模拟数据（可自定义天体数和每天体记录数） | `python3 generate_astronomical_data.py --num_sources 5000 --records_per_source 100 --output generated_data_large.csv` |
| `timestamp_solution.py` | 处理历史时间戳、优化数据并导入TDengine（超级表方案） | `python3 timestamp_solution.py --input generated_data_large.csv --db sensor_db_5000_super --mode super` |
| `quick_import.py` | 快速将优化后的数据以“按id建表”方式导入TDengine | `python3 quick_import.py --input generated_data_large.csv --db sensor_db_5000_byid --mode byid` |
| `performance_test_with_csv.py` | 对指定天体在不同时间段做查询性能测试，结果导出为CSV | `python3 performance_test_with_csv.py --db sensor_db_5000_super --source_id 1` |
| `query_performance_test.py` | 另一套查询性能测试脚本，支持自定义SQL和多天体 | `python3 query_performance_test.py --db sensor_db_5000_super --source_id 1` |
| `verify_import.py` | 校验数据导入的完整性和正确性 | `python3 verify_import.py --db sensor_db_5000_super` |
| `setup_database.py` | 数据库初始化和结构创建脚本 | `python3 setup_database.py --db sensor_db_5000_super` |
| `db_info.sh` | 查询TDengine数据库状态、表结构等信息 | `bash db_info.sh` |
| `query_functions.py` | 查询相关的Python函数库，供其他脚本调用 | 作为模块被其他脚本import |
| `spatial_queries.sql` | 空间相关SQL查询示例 | `taos -f spatial_queries.sql` 或复制到TDengine控制台执行 |
| `timestamp_solution_summary.md` | 时间戳处理方案详细文档 | 文档，无需运行 |
| `README.md` | 项目总说明文档 | 文档，无需运行 |
| `command.md` | 常用命令简要记录 | 文档，无需运行 |

## 2. 数据文件

| 文件名 | 作用说明 |
|--------|----------|
| `generated_data.csv` | 默认生成的100万条天文观测原始数据 |
| `generated_data_large.csv` | 5000天体×100条的观测数据（50万条） |
| `optimized_data_2011.csv` | 针对2011年历史数据优化后的数据 |
| `optimized_data.csv` | 优化后的主数据文件 |
| `merged_all.csv` | 合并后的大数据集 |
| `query_result_source_1_1_week.csv` | 查询性能测试结果（最近一周，超级表） |
| `query_result_source_1_1_month.csv` | 查询性能测试结果（最近一月，超级表） |
| `query_result_source_1_1_quarter.csv` | 查询性能测试结果（最近一季度，超级表） |
| `byid_query_result_source_1_1_week.csv` | 查询性能测试结果（最近一周，按id建表） |
| `byid_query_result_source_1_1_month.csv` | 查询性能测试结果（最近一月，按id建表） |
| `byid_query_result_source_1_1_quarter.csv` | 查询性能测试结果（最近一季度，按id建表） |
| `performance_test_results_source_1.csv` | 超级表方案的性能测试汇总 |
| `byid_performance_test_results_source_1.csv` | 按id建表方案的性能测试汇总 |

## 3. 其他导入脚本（高性能/实验性）

| 文件名 | 作用说明 | 使用方法 |
|--------|----------|----------|
| `turbo_import.py` | 高速批量导入脚本（实验/优化版） | `python3 turbo_import.py --input xxx.csv --db sensor_db_xxx` |
| `ultra_fast_import.py` | 极致加速导入脚本（实验/优化版） | `python3 ultra_fast_import.py --input xxx.csv --db sensor_db_xxx` |
| `fast_import.py` | 快速导入脚本（基础版） | `python3 fast_import.py --input xxx.csv --db sensor_db_xxx` |
| `improved_import.py` | 改进型导入脚本 | `python3 improved_import.py --input xxx.csv --db sensor_db_xxx` |

## 4. 其他

| 文件名 | 作用说明 |
|--------|----------|
| `connector.tar.gz` | 相关依赖或驱动包 |
| `__pycache__/` | Python缓存目录，无需关心 |

---

## 使用建议

1. **数据生成**  
   先用 `generate_astronomical_data.py` 生成所需规模的数据。
2. **数据导入**  
   - 历史数据/超级表方案：用 `timestamp_solution.py`  
   - 按id建表方案：用 `quick_import.py`
3. **性能测试**  
   用 `performance_test_with_csv.py` 或 `query_performance_test.py` 测试查询效率。
4. **结果分析**  
   查看各类 `*_result_*.csv` 文件，或用 pandas 进一步分析。
5. **数据库管理**  
   用 `db_info.sh` 查看数据库状态。

---

如需详细参数说明，可直接运行脚本加 `--help` 查看。例如：
```bash
python3 generate_astronomical_data.py --help
```

如需对某个脚本的具体参数或用法有疑问，可随时问我！
