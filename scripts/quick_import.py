#!/usr/bin/env python3
"""
TDengine Healpix ç©ºé—´åˆ†ææ•°æ®å¯¼å…¥å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨è®¡ç®— healpix åˆ†åŒº
2. è‡ªé€‚åº”åˆ†åŒºç­–ç•¥
3. é«˜æ€§èƒ½æ‰¹é‡å¯¼å…¥
4. å®Œæ•´é”™è¯¯å¤„ç†å’Œè¿›åº¦æ˜¾ç¤º
5. ç”Ÿæˆæ˜ å°„è¡¨å’Œç»Ÿè®¡ä¿¡æ¯

ä½¿ç”¨æ–¹æ³•ï¼š
python3 quick_import_healpix_enhanced.py --input data.csv --db sensor_db_healpix --nside_base 64 --nside_fine 256
"""

import pandas as pd
import taos
import time
import argparse
import healpy as hp
import numpy as np
from tqdm import tqdm
import os
import sys
from datetime import datetime

# é…ç½®å‚æ•°
DEFAULT_HOST = "localhost"
DEFAULT_USER = "root"
DEFAULT_PASSWORD = "taosdata"
DEFAULT_PORT = 6030

# è‡ªé€‚åº”åˆ†å—å‚æ•°
DEFAULT_NSIDE_BASE = 64
DEFAULT_NSIDE_FINE = 256
DEFAULT_COUNT_THRESHOLD = 10000  # æ¯ä¸ªåŒºå—æœ€å¤§å¤©ä½“æ•°
DEFAULT_BATCH_SIZE = 500


def print_banner():
    """æ‰“å°ç¨‹åºæ ‡é¢˜"""
    print("=" * 80)
    print("ğŸŒŸ TDengine Healpix ç©ºé—´åˆ†ææ•°æ®å¯¼å…¥å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰")
    print("ğŸ“Š æ”¯æŒè‡ªé€‚åº”ç©ºé—´åˆ†åŒºã€é«˜æ€§èƒ½æ‰¹é‡å¯¼å…¥")
    print("ğŸš€ ç‰ˆæœ¬ï¼š2.0")
    print("=" * 80)


def drop_target_database(db_name, host=DEFAULT_HOST, user=DEFAULT_USER, password=DEFAULT_PASSWORD, port=DEFAULT_PORT):
    """åˆ é™¤ç›®æ ‡æ•°æ®åº“"""
    try:
        conn = taos.connect(host=host, user=user, password=password, port=port)
        cursor = conn.cursor()
        cursor.execute("SHOW DATABASES")
        dbs = [row[0] for row in cursor.fetchall()]
        if db_name in dbs:
            print(f"âš ï¸  æ­£åœ¨åˆ é™¤æ•°æ®åº“: {db_name}")
            cursor.execute(f"DROP DATABASE IF EXISTS {db_name}")
            print(f"âœ… æ•°æ®åº“ {db_name} å·²åˆ é™¤")
        else:
            print(f"â„¹ï¸  æ•°æ®åº“ {db_name} ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤")
        conn.close()
        return True
    except Exception as e:
        print(f"âŒ åˆ é™¤æ•°æ®åº“å¤±è´¥: {e}")
        return False


def create_super_table(db_name, host=DEFAULT_HOST, user=DEFAULT_USER, password=DEFAULT_PASSWORD, port=DEFAULT_PORT):
    """åˆ›å»ºè¶…çº§è¡¨"""
    try:
        conn = taos.connect(host=host, user=user, password=password, port=port)
        cursor = conn.cursor()
        cursor.execute(f"CREATE DATABASE IF NOT EXISTS {db_name}")
        cursor.execute(f"USE {db_name}")
        cursor.execute("""
            CREATE STABLE IF NOT EXISTS sensor_data (
                ts TIMESTAMP,
                ra DOUBLE,
                dec DOUBLE,
                mag DOUBLE,
                jd_tcb DOUBLE
            ) TAGS (healpix_id BIGINT, source_id BIGINT)
        """)
        conn.close()
        print(f"âœ… è¶…çº§è¡¨ sensor_data å·²åˆ›å»ºï¼Œæ ‡ç­¾ä¸º healpix_id, source_id")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºè¶…çº§è¡¨å¤±è´¥: {e}")
        return False


def assign_adaptive_healpix_id(df, nside_base=DEFAULT_NSIDE_BASE, nside_fine=DEFAULT_NSIDE_FINE, count_threshold=DEFAULT_COUNT_THRESHOLD):
    """è‡ªé€‚åº”åˆ†é… healpix ID"""
    print(f"ğŸ”§ å¼€å§‹è‡ªé€‚åº” healpix åˆ†åŒºè®¡ç®—...")
    print(f"   - åŸºç¡€åˆ†è¾¨ç‡: nside={nside_base}")
    print(f"   - ç»†åˆ†åˆ†è¾¨ç‡: nside={nside_fine}")
    print(f"   - ç»†åˆ†é˜ˆå€¼: {count_threshold} å¤©ä½“/åŒºå—")
    
    # 1. å…ˆç”¨ä½åˆ†è¾¨ç‡åˆ†åŒº
    dec_clip = np.clip(df['dec'], -90, 90)
    df['base_healpix'] = hp.ang2pix(nside_base, np.radians(90 - dec_clip), np.radians(df['ra']), nest=True)
    
    # 2. ç»Ÿè®¡æ¯ä¸ªåŒºå—å¤©ä½“æ•°
    counts = df.groupby('base_healpix').size().to_dict()
    
    print(f"ğŸ“Š åŸºç¡€åˆ†åŒºç»Ÿè®¡:")
    print(f"   - æ€»åŒºå—æ•°: {len(counts)}")
    print(f"   - å¹³å‡å¤©ä½“/åŒºå—: {np.mean(list(counts.values())):.1f}")
    print(f"   - æœ€å¤§å¤©ä½“/åŒºå—: {max(counts.values())}")
    
    # ç»Ÿè®¡éœ€è¦ç»†åˆ†çš„åŒºå—
    large_blocks = {k: v for k, v in counts.items() if v > count_threshold}
    if large_blocks:
        print(f"âš¡ éœ€è¦ç»†åˆ†çš„åŒºå—: {len(large_blocks)} ä¸ª")
        for block_id, count in sorted(large_blocks.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"   - åŒºå— {block_id}: {count} å¤©ä½“")
    else:
        print(f"âœ… æ— éœ€ç»†åˆ†ï¼Œæ‰€æœ‰åŒºå—å¤©ä½“æ•° â‰¤ {count_threshold}")
    
    # 3. å¯¹äºå¤©ä½“æ•°>é˜ˆå€¼çš„åŒºå—ï¼Œæå‡nsideç»†åˆ†
    def get_adaptive_healpix(row):
        dec_clip = np.clip(row['dec'], -90, 90)
        if counts[row['base_healpix']] > count_threshold:
            fine_id = hp.ang2pix(
                nside_fine,
                np.radians(90 - dec_clip),
                np.radians(row['ra']),
                nest=True
            )
            return (row['base_healpix'] << 32) + fine_id
        else:
            return row['base_healpix']
    
    tqdm.pandas(desc="ğŸ§® åˆ†é…è‡ªé€‚åº”healpix_id")
    df['healpix_id'] = df.progress_apply(get_adaptive_healpix, axis=1)
    
    # ç”Ÿæˆ source_id ä¸ healpix_id çš„å”¯ä¸€æ˜ å°„è¡¨
    mapping_df = df.drop_duplicates('source_id')[['source_id', 'healpix_id']]
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('output/query_results', exist_ok=True)
    
    # ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‘åå…¼å®¹ï¼‰å’Œoutputç›®å½•
    root_mapping_file = 'sourceid_healpix_map.csv'
    output_mapping_file = 'output/query_results/sourceid_healpix_map.csv'
    
    mapping_df.to_csv(root_mapping_file, index=False)
    mapping_df.to_csv(output_mapping_file, index=False)
    print(f"ğŸ’¾ å·²ä¿å­˜æ˜ å°„è¡¨åˆ° {root_mapping_file} å’Œ {output_mapping_file}ï¼Œå…± {len(mapping_df)} æ¡è®°å½•")
    
    return df


def validate_data(df):
    """éªŒè¯æ•°æ®æœ‰æ•ˆæ€§"""
    print("ğŸ” éªŒè¯æ•°æ®æœ‰æ•ˆæ€§...")
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ['ts', 'ra', 'dec', 'mag', 'jd_tcb', 'source_id']
    missing_fields = [field for field in required_fields if field not in df.columns]
    if missing_fields:
        print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
        return False
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    invalid_ra = df[(df['ra'] < 0) | (df['ra'] > 360)]
    invalid_dec = df[(df['dec'] < -90) | (df['dec'] > 90)]
    
    if len(invalid_ra) > 0:
        print(f"âš ï¸  å‘ç° {len(invalid_ra)} æ¡æ— æ•ˆèµ¤ç»æ•°æ® (åº”åœ¨ 0-360Â°)")
    if len(invalid_dec) > 0:
        print(f"âš ï¸  å‘ç° {len(invalid_dec)} æ¡æ— æ•ˆèµ¤çº¬æ•°æ® (åº”åœ¨ -90Â°åˆ°+90Â°)")
    
    # æ£€æŸ¥ç©ºå€¼
    null_counts = df.isnull().sum()
    if null_counts.sum() > 0:
        print(f"âš ï¸  å‘ç°ç©ºå€¼: {dict(null_counts[null_counts > 0])}")
    
    print(f"âœ… æ•°æ®éªŒè¯å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    return True


def import_data_to_super_table(csv_file, db_name, batch_size=DEFAULT_BATCH_SIZE, 
                              nside_base=DEFAULT_NSIDE_BASE, nside_fine=DEFAULT_NSIDE_FINE,
                              count_threshold=DEFAULT_COUNT_THRESHOLD,
                              host=DEFAULT_HOST, user=DEFAULT_USER, password=DEFAULT_PASSWORD, port=DEFAULT_PORT):
    """å¯¼å…¥æ•°æ®åˆ°è¶…çº§è¡¨"""
    print(f"\nğŸš€ å¼€å§‹å¯¼å…¥æ•°æ®åˆ°è¶…çº§è¡¨ï¼ˆæ ‡ç­¾ä¸ºhealpix_id, source_idï¼‰")
    start_time = time.time()
    
    try:
        # è¯»å–æ•°æ®
        print(f"ğŸ“– è¯»å–æ•°æ®æ–‡ä»¶: {csv_file}")
        df = pd.read_csv(csv_file)
        print(f"âœ… æˆåŠŸè¯»å– {len(df):,} æ¡è®°å½•")
        
        # éªŒè¯æ•°æ®
        if not validate_data(df):
            print("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œåœæ­¢å¯¼å…¥")
            return False
        
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶: {e}")
        return False

    # è®¡ç®— healpix åˆ†åŒºï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
    if 'healpix_id' not in df.columns:
        print("ğŸ”§ è¾“å…¥CSVæ–‡ä»¶ç¼ºå°‘ healpix_id åˆ—ï¼Œå¼€å§‹è‡ªåŠ¨è®¡ç®—...")
        df = assign_adaptive_healpix_id(df, nside_base, nside_fine, count_threshold)

    # è¿æ¥æ•°æ®åº“
    try:
        conn = taos.connect(
            host=host,
            user=user,
            password=password,
            port=port,
            database=db_name
        )
        cursor = conn.cursor()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

    # ç»Ÿè®¡ä¿¡æ¯
    total_success = 0
    total_error = 0
    unique_healpix = df['healpix_id'].nunique()
    unique_sources = df['source_id'].nunique()
    
    print(f"ğŸ“Š å¯¼å…¥ç»Ÿè®¡é¢„è§ˆ:")
    print(f"   - æ€»è®°å½•æ•°: {len(df):,}")
    print(f"   - å”¯ä¸€ healpix åˆ†åŒº: {unique_healpix:,}")
    print(f"   - å”¯ä¸€å¤©ä½“æº: {unique_sources:,}")
    print(f"   - æ‰¹å¤„ç†å¤§å°: {batch_size}")

    try:
        # æŒ‰ healpix_id å’Œ source_id åˆ†ç»„å¤„ç†
        grouped = df.groupby(['healpix_id', 'source_id'])
        total_groups = len(grouped)
        processed_groups = 0
        
        print(f"\nğŸ”„ å¼€å§‹åˆ†ç»„å¯¼å…¥ï¼Œå…± {total_groups} ä¸ªå­è¡¨...")
        
        for (healpix_id, source_id), group in tqdm(grouped, total=total_groups, desc="å¯¼å…¥åˆ†åŒº/å¤©ä½“"):
            processed_groups += 1
            
            # åˆ›å»ºå­è¡¨
            table_name = f"sensor_{healpix_id}_{source_id}"
            try:
                cursor.execute(
                    f"CREATE TABLE IF NOT EXISTS {table_name} USING sensor_data TAGS ({int(healpix_id)}, {int(source_id)})"
                )
            except Exception as e:
                print(f"\nâŒ åˆ›å»ºå­è¡¨ {table_name} å¤±è´¥: {e}")
                continue
            
            # æ‰¹é‡æ’å…¥æ•°æ®
            for i in range(0, len(group), batch_size):
                batch = group.iloc[i:i+batch_size]
                values_list = []
                
                for _, row in batch.iterrows():
                    values_list.append(
                        f"('{row['ts']}', {row['ra']}, {row['dec']}, {row['mag']}, {row['jd_tcb']})"
                    )
                
                sql = f"INSERT INTO {table_name} VALUES {','.join(values_list)}"
                
                try:
                    cursor.execute(sql)
                    total_success += len(batch)
                except Exception as e:
                    # æ‰¹é‡å¤±è´¥æ—¶é€æ¡å°è¯•
                    for _, row in batch.iterrows():
                        try:
                            single_sql = f"INSERT INTO {table_name} VALUES ('{row['ts']}', {row['ra']}, {row['dec']}, {row['mag']}, {row['jd_tcb']})"
                            cursor.execute(single_sql)
                            total_success += 1
                        except Exception as single_e:
                            total_error += 1
            
            # å®šæœŸæ˜¾ç¤ºè¿›åº¦
            if processed_groups % 100 == 0 or processed_groups == total_groups:
                elapsed = time.time() - start_time
                rate = total_success / elapsed if elapsed > 0 else 0
                print(f"\nğŸ“ˆ è¿›åº¦: {processed_groups}/{total_groups} åˆ†ç»„")
                print(f"   - æˆåŠŸ: {total_success:,}")
                print(f"   - å¤±è´¥: {total_error:,}")
                print(f"   - é€Ÿåº¦: {rate:.0f} è¡Œ/ç§’")
                
    except Exception as e:
        print(f"\nâŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {e}")
    finally:
        conn.close()
    
    # æœ€ç»ˆç»Ÿè®¡
    total_time = time.time() - start_time
    success_rate = (total_success/(total_success+total_error)*100) if (total_success+total_error) > 0 else 0
    
    # ç”Ÿæˆå¯¼å…¥æŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"output/logs/import_report_{timestamp}.txt"
    os.makedirs("output/logs", exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("ğŸŒŸ TDengine HealPix æ•°æ®å¯¼å…¥æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n")
        f.write(f"å¯¼å…¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æºæ–‡ä»¶: {csv_file}\n")
        f.write(f"ç›®æ ‡æ•°æ®åº“: {db_name}\n")
        f.write(f"åŸºç¡€NSIDE: {nside_base}\n")
        f.write(f"ç»†åˆ†NSIDE: {nside_fine}\n")
        f.write(f"ç»†åˆ†é˜ˆå€¼: {count_threshold}\n")
        f.write(f"æ‰¹å¤„ç†å¤§å°: {batch_size}\n\n")
        
        f.write("ğŸ“Š å¯¼å…¥ç»Ÿè®¡:\n")
        f.write(f"  - æ€»è®°å½•æ•°: {len(df):,}\n")
        f.write(f"  - æˆåŠŸå¯¼å…¥: {total_success:,}\n")
        f.write(f"  - å¤±è´¥è®°å½•: {total_error:,}\n")
        f.write(f"  - æˆåŠŸç‡: {success_rate:.2f}%\n")
        f.write(f"  - æ€»è€—æ—¶: {total_time:.1f} ç§’\n")
        f.write(f"  - å¯¼å…¥é€Ÿåº¦: {total_success/total_time:.0f} è¡Œ/ç§’\n" if total_time > 0 else "  - å¯¼å…¥é€Ÿåº¦: N/A\n")
        
        f.write("\nğŸ—ï¸ è¡¨ç»“æ„ç»Ÿè®¡:\n")
        f.write(f"  - HealPixåˆ†åŒºæ•°: {unique_healpix:,}\n")
        f.write(f"  - å¤©ä½“æºæ•°: {unique_sources:,}\n")
        f.write(f"  - å­è¡¨æ•°é‡: {total_groups:,}\n")
        
        f.write("\nğŸ“ è¾“å‡ºæ–‡ä»¶:\n")
        f.write(f"  - æ˜ å°„æ–‡ä»¶: sourceid_healpix_map.csv\n")
        f.write(f"  - æ˜ å°„æ–‡ä»¶å‰¯æœ¬: output/query_results/sourceid_healpix_map.csv\n")
        f.write(f"  - å¯¼å…¥æŠ¥å‘Š: {report_file}\n")

    print(f"\n{'='*60}")
    print(f"ğŸ‰ å¯¼å…¥å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå¯¼å…¥: {total_success:,} æ¡")
    print(f"âŒ å¤±è´¥: {total_error:,} æ¡")
    print(f"ğŸ“Š æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
    print(f"ğŸš€ å¯¼å…¥é€Ÿåº¦: {total_success/total_time:.0f} è¡Œ/ç§’" if total_time > 0 else "N/A")
    print(f"ğŸ“ å­è¡¨æ•°é‡: {total_groups}")
    print(f"ğŸ’¾ æ˜ å°„æ–‡ä»¶: sourceid_healpix_map.csv")
    print(f"ğŸ“„ å¯¼å…¥æŠ¥å‘Š: {report_file}")
    print(f"{'='*60}")
    
    return total_success > 0


def main():
    parser = argparse.ArgumentParser(
        description="TDengine Healpix ç©ºé—´åˆ†ææ•°æ®å¯¼å…¥å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python3 %(prog)s --input data.csv --db sensor_db_healpix
  python3 %(prog)s --input data.csv --db sensor_db_healpix --nside_base 128 --count_threshold 5000
  python3 %(prog)s --input data.csv --db sensor_db_healpix --batch_size 1000 --host 192.168.1.100
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--input", type=str, required=True, help="è¾“å…¥CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--db", type=str, required=True, help="TDengineæ•°æ®åº“å")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--nside_base", type=int, default=DEFAULT_NSIDE_BASE, 
                       help=f"åŸºç¡€healpixåˆ†è¾¨ç‡ (é»˜è®¤: {DEFAULT_NSIDE_BASE})")
    parser.add_argument("--nside_fine", type=int, default=DEFAULT_NSIDE_FINE, 
                       help=f"ç»†åˆ†healpixåˆ†è¾¨ç‡ (é»˜è®¤: {DEFAULT_NSIDE_FINE})")
    parser.add_argument("--count_threshold", type=int, default=DEFAULT_COUNT_THRESHOLD, 
                       help=f"ç»†åˆ†é˜ˆå€¼ (é»˜è®¤: {DEFAULT_COUNT_THRESHOLD})")
    parser.add_argument("--batch_size", type=int, default=DEFAULT_BATCH_SIZE, 
                       help=f"æ‰¹å¤„ç†å¤§å° (é»˜è®¤: {DEFAULT_BATCH_SIZE})")
    
    # æ•°æ®åº“è¿æ¥å‚æ•°
    parser.add_argument("--host", type=str, default=DEFAULT_HOST, help=f"TDengineä¸»æœº (é»˜è®¤: {DEFAULT_HOST})")
    parser.add_argument("--user", type=str, default=DEFAULT_USER, help=f"ç”¨æˆ·å (é»˜è®¤: {DEFAULT_USER})")
    parser.add_argument("--password", type=str, default=DEFAULT_PASSWORD, help=f"å¯†ç  (é»˜è®¤: {DEFAULT_PASSWORD})")
    parser.add_argument("--port", type=int, default=DEFAULT_PORT, help=f"ç«¯å£ (é»˜è®¤: {DEFAULT_PORT})")
    
    # æ“ä½œé€‰é¡¹
    parser.add_argument("--drop_db", action="store_true", help="å¯¼å…¥å‰åˆ é™¤æ•°æ®åº“")
    parser.add_argument("--skip_validation", action="store_true", help="è·³è¿‡æ•°æ®éªŒè¯")
    
    args = parser.parse_args()
    
    # æ‰“å°ç¨‹åºä¿¡æ¯
    print_banner()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    file_size = os.path.getsize(args.input) / (1024 * 1024)  # MB
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input} ({file_size:.1f} MB)")
    print(f"ğŸ¯ ç›®æ ‡æ•°æ®åº“: {args.db}")
    print(f"ğŸ  TDengineä¸»æœº: {args.host}:{args.port}")
    
    # åˆ é™¤æ•°æ®åº“ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.drop_db:
        if not drop_target_database(args.db, args.host, args.user, args.password, args.port):
            print("âŒ åˆ é™¤æ•°æ®åº“å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            sys.exit(1)
    
    # åˆ›å»ºè¶…çº§è¡¨
    if not create_super_table(args.db, args.host, args.user, args.password, args.port):
        print("âŒ åˆ›å»ºè¶…çº§è¡¨å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        sys.exit(1)
    
    # å¯¼å…¥æ•°æ®
    success = import_data_to_super_table(
        args.input, args.db, args.batch_size, 
        args.nside_base, args.nside_fine, args.count_threshold,
        args.host, args.user, args.password, args.port
    )
    
    if success:
        print("\nğŸŠ æ•°æ®å¯¼å…¥æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ 'bash db_info.sh' æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€")
        sys.exit(0)
    else:
        print("\nğŸ’¥ æ•°æ®å¯¼å…¥å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main() 